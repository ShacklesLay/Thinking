---
title: "systhetic-data"
date: 2024-07-05
---
[The Bitter Lesson (incompleteideas.net)](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
从70年的人工智能研究中可以得出的最大教训是，利用计算的通用方法最终是最有效的，而且差距很大。这背后的根本原因是摩尔定律，或者更准确地说，是计算单位成本持续指数级下降的推广。大多数人工智能研究都是在假设代理可用的计算量是恒定的情况下进行的（在这种情况下，利用人类知识是提高性能的唯一途径之一），但在略长于典型研究项目的时间内，可用的计算量不可避免地大幅增加。研究人员寻求在短期内取得差异化改进，试图利用他们对领域的人类知识，但从长远来看，唯一重要的是利用计算。这两者不必相互对立，但实践中往往是这样。在一个方面花费的时间就是没有在另一个方面花费的时间。对投资于这种或那种方法有心理上的承诺。而且，基于人类知识的方法倾向于以使其不太适合利用计算的通用方法的方式复杂化方法。有许多例子表明人工智能研究者迟来的学习到这个苦涩的教训，回顾其中一些最突出的例子具有教育意义。

在计算机象棋中，1997年击败世界冠军卡斯帕罗夫的方法是基于大规模深度搜索的。当时，大多数计算机象棋研究者对此表示失望，他们追求的方法是利用人类对象棋特殊结构的理解。当一个更简单、基于特殊硬件和软件的搜索方法被证明远远更有效时，这些基于人类知识的象棋研究者并不是好的输家。他们说，这次“暴力搜索”可能赢了，但它不是一种通用策略，而且这不是人们下象棋的方式。这些研究者希望基于人类输入的方法获胜，并对其失败感到失望。

计算机围棋的研究进展也呈现了类似的模式，只是进一步推迟了20年。最初的巨大努力是为了避免搜索，通过利用人类知识或游戏的特殊特征，但一旦在规模上有效应用搜索，所有这些努力都证明是无关紧要的，甚至更糟。同样重要的是，通过自我对弈学习价值函数的使用（正如在许多其他游戏中，甚至在1997年首次击败世界冠军的程序中，尽管学习在其中并未发挥重要作用）。通过自我对弈学习，以及一般的学习，就像搜索一样，它使得可以利用大量计算。搜索和学习是利用大量计算在人工智能研究中的两个最重要的技术类别。在计算机围棋中，就像在计算机象棋中一样，研究人员的最初努力是利用人类理解（从而减少搜索的需要），只有在很晚时候，通过接受搜索和学习，才取得了更大的成功。

在语音识别中，1970年代由DARPA赞助的一场早期比赛中，参赛者包括利用人类知识的许多特殊方法——对词语、音素、人类声道等的知识。另一方面是更加统计性质的新方法，进行了更多的计算，基于隐马尔可夫模型（HMMs）。同样，统计方法胜过了基于人类知识的方法。这导致了自然语言处理领域的一次重大变革，逐渐在几十年中发生，统计和计算开始主导这个领域。深度学习在语音识别中的崛起是这一一贯方向上的最新步骤。深度学习方法更少依赖于人类知识，使用更多的计算，结合在巨大训练集上的学习，产生了戏剧性地更好的语音识别系统。就像在游戏中一样，研究人员总是试图制作工作方式与研究人员认为自己的思维方式相同的系统——他们试图将这种知识放入他们的系统中——但最终这证明是完全适得其反的，是研究人员时间的巨大浪费，当通过摩尔定律，大量计算变得可用并找到将其有效利用的方法时。

在计算机视觉中，也出现了类似的模式。早期方法设想的视觉是搜索边缘、或广义圆柱体、或SIFT特征的方式。但今天，所有这些都被抛弃了。现代深度学习神经网络只使用卷积的概念和某些种类的不变性，并且表现得更好。

这是一个重要的教训。作为一个领域，我们仍然没有彻底学会它，因为我们继续犯着同样的错误。要看到这一点，并有效地抵制它，我们必须理解这些错误的吸引力。我们必须学习这个苦涩的教训，即构建我们认为我们是如何思考的方式从长远来看不起作用。苦涩的教训基于历史观察，即1) 人工智能研究者经常试图将知识构建到他们的代理中，2) 这在短期内总是有帮助的，并且对研究人员个人来说是令人满意的，但3) 从长远来看它会达到平台期甚至阻碍进一步的进展，和4) 突破性进展最终通过基于扩展计算的搜索和学习的相反方法到来。最终的成功带有苦涩，并且通常消化不良，因为它是在一种受青睐的，以人为中心的方法上取得的成功。

从苦涩的教训中应该学到的一件事是通用方法的巨大力量，即随着可用计算量的增加而继续扩展的方法。在这方面似乎可以任意扩展的两种方法是搜索和学习。

从苦涩的教训中应该学到的第二个一般性观点是，心灵的实际内容是极其复杂的，不可救药的复杂；我们应该停止尝试寻找简单的方式来思考心灵的内容，如简单的方式来思考空间、对象、多个代理或对称性。所有这些都是任意的，内在复杂的，外部世界的一部分。它们不应该是内置的，因为它们的复杂性是无穷的；相反，我们应该内置只能发现和捕捉这种任意复杂性的元方法。这些方法的本质是它们可以找到好的近似，但寻找它们应该通过我们的方法，而不是我们自己。我们希望AI代理能够像我们一样发现，而不是包含我们已经发现的内容。内置我们的发现只会使看到发现过程如何进行变得更加困难。
